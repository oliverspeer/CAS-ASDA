
---
title: "sharing_speeroli"
author: "Oliver Speer"
editor: source
lang: de
language: 
  title-block-author-single: "Autor:"
  title-block-published: "Version vom:"
date: "`r Sys.Date()`"
format:
  html:
    embed-resources: true
    theme: cosmo
    toc: true
    toc-depth: 3
    toc-title: Inhalt
    toc-location: right
    code-fold: true
    code-tools: true
    css: styles.css
---





![Scooter in Winti](scooter.png){width=50% fig-align="left"}


```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(GGally)
library(flextable)
library(skimr)
load("sharing_2024.rda") #C:\\ZHAW CAS datascience\\CAS-ASDA\\

# sort rows with NA into a new dataframe
sharing_na <- sharing[!complete.cases(sharing),]
sharing.t <- sharing[complete.cases(sharing),]

```

# Prognose von Nutzerzahlen eines Sharing-Angebots {.justify}


### Hintergrund und Problemstellung {.justify}
Ein Sharing-Dienst erfasst die stündlichen Nutzerzahlen (`user`) über einen Zeitraum von 163 Tagen. Die zugehörigen Daten bestehen aus 3.912 Beobachtungen, die Informationen zu Tages- und Stundenangaben (`tag`, `stunde`), dem Wochentag (`wochentag`), Feiertagen (`feiertag`), der Temperatur (`temp`) sowie der Regenmenge (`regen`) umfassen.   
Ziel ist es, die Nutzerzahlen zu modellieren, unter Berücksichtigung von Tageszeiten, Wochentagen und Wetterbedingungen. Mit einem resultierenden Modell sollen Vorhersagen für Tage mit fehlenden Nutzerzahlen erstellt werden.

### Datenstruktur {.justify}
Die Variablen im Datensatz haben folgende Eigenschaften:  
- **Nutzerzahlen (`user`)**: Stündliche Zähldaten, teilweise fehlend.  
- **Tages- und Stundenangaben (`tag`, `stunde`)**: Numerische Variablen, die die zeitliche Struktur der Daten abbilden.  
- **Wochentag (`wochentag`)**: Kategorische Variable (z. B. Montag, Dienstag), die   wöchentliche Muster sichtbar macht.  
- **Feiertag (`feiertag`)**: Kategorische Variable (TRUE/FALSE), um Feiertagseffekte zu analysieren.  
- **Temperatur (`temp`) & Regenmenge (`regen`)**: Numerische Variablen, die wetterbedingte Einflüsse widerspiegeln.  
 

### Methodisches Vorgehen {.justify}
1. **Deskriptive Analyse**:
   - Die stündlichen Nutzerzahlen wurden auf tageszeitliche und wöchentliche Schwankungen, sowie Einflüsse von Wetterbedingungen untersucht.

2. **Modellierung**:
   - Aufgrund der Zähldaten wurden Poisson- und Negative-Binomial-Modelle angewandt. Letzteres erwies sich als geeigneter, da die Nutzerzahlen Überdispersion zeigen (die Streuung ist größer als bei einer Poisson-Verteilung erwartet).
   - Die Modelle integrieren zeitliche Effekte (Tageszeit, Wochentag) sowie wetterbezogene Variablen (Temperatur, Regen).

3. **Prognose fehlender Werte**:
   - Für Tage ohne Nutzerzahlen wurden mit dem Negativ-Binomial-Modell Vorhersagen erstellt. Zur Quantifizierung der Unsicherheiten wurden 95%-Prognoseintervalle berechnet.

4. **Visualisierung**:
   - Die Ergebnisse wurden als Zeitreihen dargestellt, wobei die beobachteten Nutzerzahlen, die prognostizierten Werte und die Prognoseintervalle klar differenziert wurden. 


# Explorative Datenanalyse {.justify}

```{r echo=FALSE, message=FALSE, warning=FALSE}
#g <- glimpse(sharing)
ft <- flextable(skim(sharing)) |> 
  set_header_labels(skim_type = "Datentyp",
                    skim_variable = "Variable",
                    n_missing = "Fehlende Werte",
                    n = "Anzahl",
                    numeric.mean = "Mittelwert",
                    numeric.sd = "Standardabweichung",
                    numeric.p25 = "25%-Quantil",
                    numeric.p50 = "50%-Quantil",
                    numeric.p75 = "75%-Quantil",
                    numeric.p0 = "Minimum",
                    numeric.p100 = "Maximum",
                    numeric.hist = "Histogramm",
                    factor.n_unique =" Anzahl Faktoren") |> 
  autofit() |>
  bold(part = "header") |>
  align(align = "center", part = "all")
ft
```


Ausser den 456 fehlenden Nutzerzahlen, die nach der Modellierung prognostiziert werden sollen, sind keine weiteren fehlenden Werte vorhanden.

In der Variable `user` sind `r sum(sharing$user == 0, na.rm = TRUE)` Nullen und `r sum(sharing$user == !floor(sharing$user), na.rm = TRUE)` Kommazahlen enthalten. D.h. die Zielgrösse `user` ist eine Zähldatenvariable und könnte als Poisson- oder Negativ-Binomial-Verteilung modelliert werden. Da der Anteil der Nullen sehr gering ist, ist ein zero-inflated Modell nicht notwendig.

## Graphische Darstellungen {.justify}

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  # mutate(stunde = as.factor(stunde)) |>
  # group_by(wochentag) |>
  dplyr::select(user, temp, regen, stunde, tag, wochentag, feiertag) |>
  ggpairs( aes(color = wochentag),
           lower = list(continuous = "autopoint"),
           upper = list(continuous = "points")#,
#           diag = list(continuous = "barDiag")
  )
```
In der oberen globalen Übersicht sind die ersten, nicht linearen Zusammenhänge zwischen den Variablen ersichtlich. Wie etwa die tageszeitliche Änderung der Temperatur oder die tageszeitlichen und Wochentags-Abhängigkeit der Nutzerzahlen.  

Es werden im folgenden einzelne Variablen und deren Zusammenhänge individuell betrachtet.

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  dplyr::select(user, temp) |> 
  ggplot(aes(x = user)) +
  geom_histogram(fill = "lightblue", color = "black", binwidth = 1) +
  labs(title = "Verteilung der Nutzerzahlen",
       x = "Nutzer pro Stunde",
       y = "Häufigkeit")+
  theme_minimal()
```

Die Verteilung der Nutzerzahlen ist deutlich rechtsschief. Der Erwarungswert $\lambda$ beträgt rund `r round(mean(sharing$user, na.rm = TRUE),0)` und die Varianz beträgt rund `r format(var(sharing$user, na.rm = TRUE), big.mark = "'", scientific = FALSE, digits = 1)`. Zusammen mit der Rechtsschiefe und der Überdispersion ist es sinnvoll Poisson- und Negativ-Binomial-Modelle miteinander zu vergleichen.

### Nutzerzahlen nach Wochentag, Feiertag und Tageszeit {.justify}

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  group_by(wochentag) |>
  na.omit() |>
  ggplot(aes(x = wochentag)) +
  geom_boxplot(aes(y = user, colour = feiertag)) +
  labs(title = "Nutzerzahlen nach Wochentag",
       x = " ",
       y = "Nutzer pro Stunde",
       colour = "Feiertag")+
  theme_minimal()

```

Die Nutzerzahlen an Feiertagen unterscheiden sich zum Teil von den Nutzerzahlen an Werktagen. Beide Prädiktoren sollten also bei den Modellen berücksichtigt werden.

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(stunde = as.factor(stunde)) |>
  group_by(wochentag) |>
  na.omit() |>
  ggplot(aes(x = wochentag)) +
  geom_boxplot(aes(y = user, colour = stunde)) +
  labs(title = "Nutzerzahlen je Wochentag",
       x = " ",
       y = "Nutzer pro Stunde",
       colour = "Uhrzeit")+
  theme_minimal()

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(stunde = as.factor(stunde)) |>
  group_by(stunde) |>
  na.omit() |>
  ggplot(aes(x = stunde)) +
  geom_boxplot(aes(y = user, colour = wochentag)) +
  labs(title = "Nutzerzahlen nach Tageszeit",
       x = "Uhrzeit",
       y = "Nutzer pro Stunde",
       colour = "Wochentag")+
  theme_minimal()

```

Wie zu erwarten variieren die Nutzerzahlen in Abhängigkeit von der Tageszeit, als auch in Abhängigkeit vom Wochentag. Beide Prädiktoren sollten also bei den Modellen als Interaktion berücksichtigt werden. Beide Prädiktoren scheinen eine nicht-lineare Beziehung zu den Nutzerzahlen zu haben. Die Schwingung bestätigt sich auch, wenn die Nutzerzahlen über die Zeit aufgetragen werden. Im STL Plot unten zeigt sich eine Schwingung (saisonaler Anteil), der hier als harmonisch interpretiert wird.

::: {.panel-tabset}
## Nutzerzahlen über die Zeit
```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(ID = row_number()) |>
  ggplot(aes(x = ID, y = user)) +
  #geom_point() +
  geom_line() +
  #geom_line(aes(y = predicted_user), color = "blue") +
  labs(title = " ",
       x = "Zeit [h]",
       y = "Nutzer pro Stunde")+
  theme_minimal()
```

## STL Plot

```{r echo=FALSE, message=FALSE, warning=FALSE} 
ts <- ts(sharing.t$user, frequency = 24)
stl_user <- stl(ts, s.window = "periodic")
plot(stl_user)
decomp <- decompose(ts)
u.trend <- decomp$trend
u.sais <- decomp$seasonal
```

:::

### Zusammenhang zwischen Nutzerzahlen, Temperatur und Regen {.justify}


#### Nutzerzahlen und Temperatur {.justify}


```{r echo=FALSE, message=FALSE, warning=FALSE}
# ggplot user over temp coloured by wochentag
sharing |> 
  ggplot(aes(x = temp, y = user)) +
  geom_point() +
  geom_smooth(method = "gam") +
  labs(title = " ",
       x = "Temperatur [°C]",
       y = "Nutzer pro Stunde")+
  theme_minimal()


```

Nicht überraschend hat die Temperatur einen Einfluss auf die Nutzerzahlen. Die Nutzerzahlen steigen mit zunehmender Temperatur. 

::: {.panel-tabset}
## Temperatur über die Zeit
```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(ID = row_number()) |>
  ggplot(aes(x = ID, y = temp)) +
  geom_line() +
  labs(title = " ",
       x = "Zeit [h]",
       y = "Temperatur [°C]")+
  theme_minimal()
```

## STL Plot

```{r echo=FALSE, message=FALSE, warning=FALSE}
temp.ts <- ts(sharing.t$temp, frequency = 24)
# acf(temp.ts, lag.max = 24*7, main = "Autokorrelation der Temperatur")
stl_temp <- stl(temp.ts, s.window = "periodic")
plot(stl_temp)
#decomp <- decompose(temp.ts)
#plot(decomp)
#t.trend <- decomp$trend
```

:::


```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(ID = row_number()) |>
  ggplot(aes(x = stunde, y = temp)) +
  geom_point() +
  labs(title = "Temperatur über die Tageszeit",
       x = "Tageszeit [h]",
       y = "Temperatur [°C]")+
  theme_minimal()
```



Die Temperatur ist wie zu erwarten deutlich abhängig von der Tageszeit (saisonaler Anteil im STL Plot oben), vermutlich eine harmonische Schwingung über den Tagesverlauf.. Die Temperatur zeigt zusätzlich einen Trend-Anteil, das Wetter.  

Die Verteilung der Regenmengen werden sicher ein anderes Bild zeigen.

#### Nutzerzahlen und Regen {.justify}


```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing |> 
  mutate(ID = row_number()) |>
  ggplot(aes(x = ID, y = regen)) +
  geom_line() +
  geom_point()+
  labs(title = "Regenmenge über die Zeit",
       x = "Zeit [h]",
       y = "Regen [mm]")+
  theme_minimal()


```

Bei der Mehrheit der Zeitpunkte, `r sum(sharing$regen == 0)` wird kein Niederschlag nachgewiessen. An `r sum(sharing$regen > 0 & sharing$regen < 5, na.rm = TRUE)` Zeitpunkten ist die Regenmenge kleiner als 5mm/h und an `r sum(sharing$regen > 5, na.rm = TRUE)` Zeitpunkten ist die Regenmenge grösser als 5mm/h. 

Es ist fraglich ob die Regenmenge als kontinuierliche Variable oder besser als kategorische Variable modelliert werden soll. Eine Möglichkeit wäre die Regenmenge in 2 Kategorien zu unterteilen:\
kein Regen = 0 und Regen = 1.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# ggplot user over regen coloured by wochentag
sharing |> 
  ggplot(aes(x = regen, y = user)) +
  geom_point() +
  labs(title = "Nutzerzahlen über Regen",
       x = "Regen [mm/h]",
       y = "Nutzer pro Stunde")+
  theme_minimal()



```


### Zusammenfassung der deskriptiven Datenanalyse {.justify}

-   Zielgrösse `user` in Poisson- oder Negativ-Binomial-Verteilung
-   Prädiktoren: `temp`, `regen`, `feiertag`, `wochentag`, `stunde`, `tag`
-   Interaktionen: `temp:stunde`, `temp:tag`, `feiertag:stunde`, `wochentag:stunde`
-   Nicht-lineare Beziehungen: `stunde`, `tag` als Sinus- und Cosinusfunktion modellieren
-   Prädiktor `regen` als kategorische Variable mit 0 und 1 modellieren



# Modellierung {.justify}

### Einfaches Poisson-Modell ohne Interaktionen & Schwingungen {.justify}

```{r, echo=F, message=F, warning=F}
sharing.t <-sharing.t |> 
  mutate(regen.bin = as.factor(ifelse(regen == 0, 0, 1)))
fit <- glm(user ~ temp + regen + feiertag + wochentag + stunde + tag, data = sharing.t, family = poisson)
fit.rb <- glm(user ~ temp + regen.bin + feiertag + wochentag + stunde + tag, data = sharing.t, family = poisson)
```

::: {.panel-tabset}
## Modell
```{r echo=FALSE, message=FALSE, warning=FALSE}
fit$formula
```

## summary

```{r, echo=F, message=F, warning=F}
summary(fit)
```

## drop1

```{r, echo=F, message=F, warning=F}
drop1(fit, test = "F")
```

:::


In diesem ersten rudimentären Model tragen alle Prädiktoren signifikant zur Erklärung der Zielgrösse `user` bei. Die Überdispersion ist deutlich. 
```{r, echo=F, message=F, warning=F}
par(mfrow=c(2,2))
plot(fit)

```

Zu beachten ist der Hebel des Datenpunkts #1512 (mit fast 25mm/h) im Leverage Plot.  
Die Residuen sind nicht homogen verteilt.  

Im folgenden wird das Modell mit `regen` als kategorische Variable modelliert.

### Model mit Regen als kategorische Variable {.justify}

```{r}
sharing.t <-sharing.t |> 
  mutate(regen.bin = as.factor(ifelse(regen == 0, 0, 1)))
```

::: {.panel-tabset}
## Modell
```{r echo=FALSE, message=FALSE, warning=FALSE}
fit.rb$formula
```

## summary

```{r, echo=F, message=F, warning=F}
summary(fit.rb)
```

## drop1

```{r, echo=F, message=F, warning=F}
drop1(fit.rb, test = "F")
```

:::

```{r, echo=F, message=F, warning=F}
par(mfrow=c(2,2))
plot(fit.rb)

```

Durch die Modellierung von `regen` als binäre kategorische Variable konnte die Devianz etwas reduziert werden. Vor allem ist die Verbesserung im Leverage Plot sichtbar. Der Hebel des Datenpunkts #1512 (mit fast 25mm/h) wurde durch die Modellierung von `regen` als binäre Faktorvariable reduziert.  
Ansonsten passt das Modell immer noch nicht gut zu den Daten.

### Poisson-Modell mit Interaktionen und Schwingungen der Tageszeiten, Wochentage und Tage {.justify}

Im folgenden werden Interaktionen und Schwingungen in das Modell integriert.


```{r, echo=F, message=F, warning=F}
fit.pois <- glm(user ~ temp * (sin(2 * pi * stunde / 24) + cos(2 * pi * stunde / 24)) + 
               feiertag * cos(2 * pi * stunde / 24) + 
               wochentag * cos(2 * pi * stunde / 24) + 
               regen.bin + 
               tag*cos(2*pi*tag/3912),
               data = sharing.t, 
             family = poisson)
```

::: {.panel-tabset}
## Modell
```{r echo=FALSE, message=FALSE, warning=FALSE}
fit.pois$formula
```

## summary
```{r, echo=F, message=F, warning=F}
s1 <- summary(fit.pois)
#fit.1$formula
s1

```

## drop1

```{r, echo=F, message=F, warning=F}
drop1(fit.pois, test = "Chisq")
```

:::

```{r, echo=F, message=F, warning=F}
par(mfrow=c(2,2))
plot(fit.pois)


```

Das Poisson-Model `fit.pois` erklärt `r round(1-s1$deviance/s1$null.deviance, 2)*100`% der Devianz. Die Devianz konnte im Vergleich zum einfachen Modell deutlich reduziert werden. Die als Schwingungen modellierten Interaktionen zwischen Temperatur und Tageszeiten, als auch zwischen Wochen- & Feiertage und Stunden haben einen signifikanten Einfluss auf die Nutzerzahlen.  
Da die Überdispersion immer noch deutlich ist, und die Verteilung der Nutzer, wie oben beschrieben, rechtsschief ist, wird im folgenden ein Modell mit negativer Binomialverteilung modelliert.

### Negativ-Binomial-Modell {.justify}

```{r, echo=F, message=F, warning=F}
#negbin
library(MASS)
fit.nb <- glm.nb(user ~ temp * (sin(2 * pi * stunde / 24) + cos(2 * pi * stunde / 24)) + 
               feiertag * cos(2 * pi * stunde / 24) + 
               wochentag * cos(2 * pi * stunde / 24) + 
               regen.bin + 
               tag*cos(2*pi*tag/3912), data = sharing.t)
```

::: {.panel-tabset}
## Modell
```{r echo=FALSE, message=FALSE, warning=FALSE}
fit.nb[["call"]][["formula"]]
```

## summary
```{r, echo=F, message=F, warning=F}
s.nb <- summary(fit.nb)
#s.nb
#1-s.nb$deviance/s.nb$null.deviance
s.nb
```

## drop1

```{r, echo=F, message=F, warning=F}
drop1(fit.nb, test = "Chisq")
```

:::

```{r, echo=F, message=F, warning=F}
par(mfrow=c(2,2))
plot(fit.nb)



```

Das negativ-binomial-Model `fit.nb` erklärt `r round(1-s.nb$deviance/s.nb$null.deviance,1)*100`% der Devianz der Nutzerzahlen. Die Devianz konnte im Vergleich zum Poisson Modell weiter reduziert werden. 
Der Scale-Location-Plot und der Residuenplot zeigen beide eine Stabilisierung gegenüber dem Poisson-Modell.
Und der AIC-Vergleich zeigt:
.
```{r echo=FALSE, message=FALSE, warning=FALSE}
df <- AIC(fit, fit.rb, fit.pois, fit.nb)
df$model <- c("fit", "fit.rb", "fit.pois", "fit.nb")
ft <- flextable::flextable(df[,c(3, 1, 2)]) |> 
  flextable::set_table_properties(width = .5)
ft
```

Die AIC Werte werden mit voranschreitender Model-Entwicklung kleiner.   
Zusammen mit der Devianz, dem guten Anteil der erklärten Deivanz und dem kleinsten AIC entscheide ich mich für das Modell `fit.nb` als das beste Modell, um die Nutzerzahlen zu erklären und prognostizieren.

## Punktvorhersagen mit 95% Prognoseintervallen {.justify}
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Vorhersagen berechnen


sharing.p <- sharing |> 
  mutate(regen.bin = as.factor(ifelse(regen == 0, 0, 1)))


#sharing.p$predicted_user <- predict(fit.pois, newdata = sharing.p, type = "response")

na.index <- which(is.na(sharing.p$user))
sharing.p$user.pred <- NA
sharing.p$user.pred[na.index] <- predict(fit.nb, newdata = sharing.p[na.index,], type = "response")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing_na.p <- sharing_na |>
  mutate(regen.bin = as.factor(ifelse(regen == 0, 0, 1)))

sharing.p <- sharing |> 
  mutate(regen.bin = as.factor(ifelse(regen == 0, 0, 1)))

na.index <- which(is.na(sharing.p$user))
```

```{r echo=T, message=FALSE, warning=FALSE}
# Prognose mit negativ-Binomial-Model (fit.nb) und 95% Konfidenzintervall
# Prognose
p <- predict(fit.nb, newdata = sharing_na.p, type = "link", se.fit = TRUE)

# Anzahl der Simulationen pro Vorhersage
nsim <- 10000

# Matrix zur Speicherung der simulierten mu-Werte
mu <- matrix(nrow = length(p$fit), ncol = nsim)

# Simulation der mu-Werte
for (i in 1:length(p$fit)) {
  mu[i, ] <- exp(rnorm(n = nsim, mean = p$fit[i], sd = p$se.fit[i]))
}

# Dispersionsparameter theta aus dem Modell
theta <- fit.nb$theta

# Matrix zur Speicherung der simulierten Beobachtungen
beob <- matrix(nrow = length(p$fit), ncol = nsim)

# Simulation der Beobachtungen
for (i in 1:length(p$fit)) {
  beob[i, ] <- rnegbin(n = nsim, mu = mu[i, ], theta = theta)
}

# Eintragen der Prognosen und der Prognose-Intervalle

sharing.p$unterer_PI <- NA
sharing.p$oberer_PI <- NA
sharing.p <- sharing.p |> 
  mutate(na.user = ifelse(is.na(user), "Prognose", "Beobachtung"))

sharing.p[na.index,] <- sharing.p[na.index,] |> 
  mutate(
    user = round(exp(p$fit), 0),
    unterer_PI = apply(beob, 1, quantile, probs = 0.025, type = 1),
    oberer_PI = apply(beob, 1, quantile, probs = 0.975, type = 1)
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
sharing.p.p <- sharing.p  |> 
  mutate(
    ID = row_number(),
    unterer_PI = if_else(is.na(unterer_PI), user, unterer_PI),
    oberer_PI = if_else(is.na(oberer_PI), user, oberer_PI)
                           
    )
```

::: {.panel-tabset}
## Prognose (graphisch)

```{r echo=FALSE, message=FALSE, warning=FALSE}

ggplot(data = sharing.p.p, aes(x = ID)) +
  # geom_ribbon(aes(ymin = unterer_PI, ymax = oberer_PI#, fill = na.user
  #                 ),  alpha = 0.5, fill = "red") +
  geom_line(aes(y = user, color = na.user, group = 1, linetype = "user")) +
  geom_line(aes(y = unterer_PI, 
                #color = na.user, group = 1, 
                linetype = "PI"), color = "#555555", alpha=0.8) +
  geom_line(aes(y = oberer_PI, 
                #color = na.user, group = 1, 
                linetype = "PI"), color = "#555555", alpha=0.8) +
  scale_color_manual(values = c("Beobachtung" = "#555555", "Prognose" = "blue")) +
  scale_linetype_manual(
    values = c("user" = "solid", "PI" = "dotted"),
    name = "Linientyp",
    labels = c("user" = "Nutzerzahlen", "PI" = "Prognoseintervall")
  ) +
  labs(title = "Nutzerzahl-Prognosen mit 95% Prognoseintervall ",
       x = "Zeit [h]",
       y = "Nutzer pro Stunde",
       fill = "na.user",
       color = NULL) +
  theme_minimal()+
  theme(legend.position = "bottom")
```

## Prognose (Tabellenansicht Tag 9)

```{r echo=FALSE, message=FALSE, warning=FALSE}
shrng_speeroli <- sharing.p[,-c(8,11)]
ft <- flextable(shrng_speeroli[190:220,])
ft
```

:::

# Fazit{.justify}
Nach der Grafik oben, die die Vorhersagen und die 95% Prognoseintervalle zeigt, können wir sehen, dass die Vorhersagen für die Nutzerzahlen in den Zeiträumen, in denen keine Daten vorliegen, relativ gut bzw. plausibel sind. Die Prognoseintervalle erscheinen jedoch relativ breit.  
Besonders geringe Nutzerzahlen, wie etwas an den Tagen 141 bis 143, sind schwer vorherzusagen, ohne weitere Angaben, wie etwa technische Probleme beim Verleiher, oder mögliche besondere Ereignisse, die die Nutzung beeinflussen könnten. Dies gilt auch für besonders hohe Nutzerzahlen, wie etwa an den Tagen 67 bis 68. 

Kulturelle oder sportliche Ereignisse, Schulferien, Strassensperrungen oder andere unvorhergesehene Ereignisse können die Nutzung stark beeinflussen. Diese können aber, ohne deren Angaben, dann auch nicht modelliert werden.
Aus dem vorliegenden Temperaturen den Datensatzes, die an wenigen Tagen fast 35°C erreichen, bleibt zu vermuten, dass die Daten im Sommer aufgenommen wurden.


Insgesamt finde ich erstaunlich wie hinreichend genau  mit nur den Angaben von Tageszeit, Wochentagen, Regen und Temperatur die Nutzerzahlen modelliert und prognostiziert werden können. Wenigstens beim vorliegenden Datensatz.


#### Speicherung der kompletierten Daten
Das ergänzte Datenfile wurde als `sharing_speeroli.rda` gespeichert.

Datenstruktur des Files:





```{r echo=FALSE, message=FALSE, warning=FALSE}
shrng_speeroli <- sharing.p[,-c(8,11)] 
save(shrng_speeroli, file = "sharing_speeroli.rda")

ft <- flextable(skim(shrng_speeroli)) |> 
  set_header_labels(skim_type = "Datentyp",
                    skim_variable = "Variable",
                    n_missing = "Fehlende Werte",
                    n = "Anzahl",
                    numeric.mean = "Mittelwert",
                    numeric.sd = "Standardabweichung",
                    numeric.p25 = "25%-Quantil",
                    numeric.p50 = "50%-Quantil",
                    numeric.p75 = "75%-Quantil",
                    numeric.p0 = "Minimum",
                    numeric.p100 = "Maximum",
                    numeric.hist = "Histogramm",
                    factor.n_unique =" Anzahl Faktoren") |> 
  autofit() |>
  bold(part = "header") |>
  align(align = "center", part = "all")
ft
```




